{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4aa09f51-c7da-4a54-98ee-a50cbe1594ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding,GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding, Conv1D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05966679-1e06-49d1-b504-8e37da09a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN custom functions\n",
    "import Tools.NN as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fedab4-775e-4975-b566-02fd2777d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./body')\n",
    "df_target = pd.read_csv('./target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6913addc-02ee-462c-a9ef-05a484b181f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df= df.merge(df_target, on = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0a4a29-99fc-4a9a-8908-7d4d3e55294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.drop('Unnamed: 0',axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c1de33-e1aa-4d49-8ef6-7713f997daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def clean_data(review):\n",
    "#     review = re.sub('[^a-zA-Z]', ' ',review)\n",
    "#     review = review.lower()\n",
    "#     return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28c29fc-c752-4751-868d-9f4a4acc2c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looking for some authentic Japanese food at re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pepe Rosso is where you go when you're in SOHO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had waited to return a couple other times to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This place is always busy - partly because it'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love this place! I am not a regular yelper I d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  Looking for some authentic Japanese food at re...       1\n",
       "1  Pepe Rosso is where you go when you're in SOHO...       1\n",
       "2  I had waited to return a couple other times to...       1\n",
       "3  This place is always busy - partly because it'...       1\n",
       "4  Love this place! I am not a regular yelper I d...       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d261b9f-0752-4acf-9176-708af4c47aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df['review'] = original_df['review'].apply(nn.clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed44b0c8-406c-40d5-ab86-4b41a1dbf619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    256887\n",
       "0     29107\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa11743a-9f05-46a2-b08a-9a1710f42044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download nltk stopwords in necessary\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d67ec46-1849-4fa5-8a78-3ff24ee42fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw = stopwords.words('english')\n",
    "# sw += ['food','place','good',\"great\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed6d87a-7bd2-4aab-b591-1b59934070a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stop_words(review):\n",
    "#     review_minus_sw = []\n",
    "#     stop_words = sw\n",
    "#     review = review.split()\n",
    "#     review = [review_minus_sw.append(word) for word in review if word not in stop_words]\n",
    "#     review = ' '.join(review_minus_sw)\n",
    "#     return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c218a9-b85f-4115-acae-a3d640f09c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df['review'] = original_df['review'].apply(nn.remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b84dca2-ec62-464c-9710-72cd94f19184",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(original_df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97970321-4f7b-4986-8253-88db90977964",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 1000)\n",
    " # Stop words are common words in English that don't tell us anything about the polarity of a review.\n",
    "    # Such words include the, that, and a\n",
    "# Converts a collection of text documents to a matrix of token counts\n",
    "# max_features = maximum number of words we'd like to have in our bag of words model\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = original_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30df373e-74d1-4471-84ed-25a2af4952eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'absolutely',\n",
       " 'accommodating',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'affordable',\n",
       " 'afternoon',\n",
       " 'ago',\n",
       " 'al',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'amazing',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'american',\n",
       " 'amount',\n",
       " 'another',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apparently',\n",
       " 'appetizer',\n",
       " 'appetizers',\n",
       " 'apple',\n",
       " 'area',\n",
       " 'around',\n",
       " 'arrived',\n",
       " 'artichoke',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'ate',\n",
       " 'atmosphere',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'authentic',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avocado',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'baked',\n",
       " 'balls',\n",
       " 'banana',\n",
       " 'banh',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'bartender',\n",
       " 'bartenders',\n",
       " 'based',\n",
       " 'basically',\n",
       " 'basil',\n",
       " 'bathroom',\n",
       " 'bbq',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'behind',\n",
       " 'believe',\n",
       " 'belly',\n",
       " 'benedict',\n",
       " 'best',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'birthday',\n",
       " 'biscuit',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bites',\n",
       " 'black',\n",
       " 'bland',\n",
       " 'block',\n",
       " 'bloody',\n",
       " 'blue',\n",
       " 'bone',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bowl',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bread',\n",
       " 'breakfast',\n",
       " 'bring',\n",
       " 'brisket',\n",
       " 'brooklyn',\n",
       " 'broth',\n",
       " 'brought',\n",
       " 'brunch',\n",
       " 'bucks',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'buns',\n",
       " 'burger',\n",
       " 'burgers',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'butter',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'calamari',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'cannot',\n",
       " 'care',\n",
       " 'cart',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'casual',\n",
       " 'certainly',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'cheese',\n",
       " 'cheesecake',\n",
       " 'chef',\n",
       " 'chewy',\n",
       " 'chicken',\n",
       " 'chili',\n",
       " 'chinatown',\n",
       " 'chinese',\n",
       " 'chips',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'city',\n",
       " 'clams',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'close',\n",
       " 'cocktail',\n",
       " 'cocktails',\n",
       " 'coconut',\n",
       " 'coffee',\n",
       " 'cold',\n",
       " 'combination',\n",
       " 'combo',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'complaint',\n",
       " 'completely',\n",
       " 'complimentary',\n",
       " 'considering',\n",
       " 'conversation',\n",
       " 'cook',\n",
       " 'cooked',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'counter',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'cozy',\n",
       " 'crab',\n",
       " 'cramped',\n",
       " 'craving',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'creamy',\n",
       " 'crisp',\n",
       " 'crispy',\n",
       " 'crowd',\n",
       " 'crowded',\n",
       " 'crunchy',\n",
       " 'crust',\n",
       " 'cuban',\n",
       " 'cuisine',\n",
       " 'cup',\n",
       " 'curry',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'damn',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'day',\n",
       " 'days',\n",
       " 'de',\n",
       " 'deal',\n",
       " 'decent',\n",
       " 'decided',\n",
       " 'decor',\n",
       " 'deep',\n",
       " 'def',\n",
       " 'definitely',\n",
       " 'delicious',\n",
       " 'delish',\n",
       " 'delivery',\n",
       " 'despite',\n",
       " 'dessert',\n",
       " 'desserts',\n",
       " 'die',\n",
       " 'different',\n",
       " 'diner',\n",
       " 'dining',\n",
       " 'dinner',\n",
       " 'dip',\n",
       " 'dipping',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'dish',\n",
       " 'dishes',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'dough',\n",
       " 'dressing',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'dry',\n",
       " 'duck',\n",
       " 'due',\n",
       " 'dumpling',\n",
       " 'dumplings',\n",
       " 'early',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eaten',\n",
       " 'eating',\n",
       " 'egg',\n",
       " 'eggplant',\n",
       " 'eggs',\n",
       " 'either',\n",
       " 'else',\n",
       " 'empanadas',\n",
       " 'empty',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enough',\n",
       " 'entire',\n",
       " 'entree',\n",
       " 'entrees',\n",
       " 'especially',\n",
       " 'establishment',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excited',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'falafel',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fancy',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'fatty',\n",
       " 'favorite',\n",
       " 'favorites',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'felt',\n",
       " 'filled',\n",
       " 'filling',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'five',\n",
       " 'flavor',\n",
       " 'flavorful',\n",
       " 'flavors',\n",
       " 'fluffy',\n",
       " 'foods',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'free',\n",
       " 'french',\n",
       " 'fresh',\n",
       " 'friday',\n",
       " 'fried',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'fries',\n",
       " 'front',\n",
       " 'fruit',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'garden',\n",
       " 'garlic',\n",
       " 'gave',\n",
       " 'gem',\n",
       " 'generous',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'ginger',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'give',\n",
       " 'given',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'glasses',\n",
       " 'gluten',\n",
       " 'gnocchi',\n",
       " 'go',\n",
       " 'goat',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'goodness',\n",
       " 'got',\n",
       " 'grab',\n",
       " 'greasy',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'greens',\n",
       " 'grilled',\n",
       " 'grits',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'halal',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hate',\n",
       " 'head',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heaven',\n",
       " 'heavy',\n",
       " 'hell',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'hit',\n",
       " 'hole',\n",
       " 'home',\n",
       " 'homemade',\n",
       " 'honestly',\n",
       " 'honey',\n",
       " 'hope',\n",
       " 'host',\n",
       " 'hostess',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'however',\n",
       " 'huge',\n",
       " 'hummus',\n",
       " 'hungry',\n",
       " 'husband',\n",
       " 'hype',\n",
       " 'ice',\n",
       " 'idea',\n",
       " 'immediately',\n",
       " 'impressed',\n",
       " 'included',\n",
       " 'including',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'ingredients',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'interesting',\n",
       " 'interior',\n",
       " 'intimate',\n",
       " 'ippudo',\n",
       " 'italian',\n",
       " 'items',\n",
       " 'japanese',\n",
       " 'job',\n",
       " 'joint',\n",
       " 'juice',\n",
       " 'juicy',\n",
       " 'kale',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kick',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'kitchen',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'known',\n",
       " 'korean',\n",
       " 'la',\n",
       " 'lamb',\n",
       " 'large',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'left',\n",
       " 'lemon',\n",
       " 'less',\n",
       " 'let',\n",
       " 'lettuce',\n",
       " 'level',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'limited',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'list',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lived',\n",
       " 'lobster',\n",
       " 'local',\n",
       " 'location',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'loud',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'lovely',\n",
       " 'low',\n",
       " 'lucky',\n",
       " 'lunch',\n",
       " 'mac',\n",
       " 'made',\n",
       " 'main',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'manager',\n",
       " 'mango',\n",
       " 'manhattan',\n",
       " 'many',\n",
       " 'market',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'mayo',\n",
       " 'meal',\n",
       " 'meals',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meat',\n",
       " 'meatball',\n",
       " 'meatballs',\n",
       " 'meats',\n",
       " 'mediocre',\n",
       " 'medium',\n",
       " 'mention',\n",
       " 'mentioned',\n",
       " 'menu',\n",
       " 'mexican',\n",
       " 'mi',\n",
       " 'middle',\n",
       " 'might',\n",
       " 'milk',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'mins',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'miso',\n",
       " 'miss',\n",
       " 'mix',\n",
       " 'mixed',\n",
       " 'modern',\n",
       " 'moist',\n",
       " 'mom',\n",
       " 'money',\n",
       " 'months',\n",
       " 'mood',\n",
       " 'morning',\n",
       " 'mostly',\n",
       " 'mouth',\n",
       " 'move',\n",
       " 'moved',\n",
       " 'mozzarella',\n",
       " 'much',\n",
       " 'mushroom',\n",
       " 'mushrooms',\n",
       " 'music',\n",
       " 'mussels',\n",
       " 'must',\n",
       " 'name',\n",
       " 'near',\n",
       " 'nearby',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needs',\n",
       " 'neighborhood',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'nicely',\n",
       " 'night',\n",
       " 'non',\n",
       " 'noodle',\n",
       " 'noodles',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'noticed',\n",
       " 'number',\n",
       " 'ny',\n",
       " 'nyc',\n",
       " 'octopus',\n",
       " 'offer',\n",
       " 'offered',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'oil',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'olive',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'onion',\n",
       " 'onions',\n",
       " 'open',\n",
       " 'opened',\n",
       " 'opinion',\n",
       " 'option',\n",
       " 'options',\n",
       " 'orange',\n",
       " 'order',\n",
       " 'ordered',\n",
       " 'ordering',\n",
       " 'orders',\n",
       " 'original',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'outdoor',\n",
       " 'outside',\n",
       " 'outstanding',\n",
       " 'oven',\n",
       " 'overall',\n",
       " 'overly',\n",
       " 'overpriced',\n",
       " 'owner',\n",
       " 'oysters',\n",
       " 'packed',\n",
       " 'pad',\n",
       " 'paid',\n",
       " 'pancake',\n",
       " 'pancakes',\n",
       " 'park',\n",
       " 'part',\n",
       " 'particularly',\n",
       " 'party',\n",
       " 'past',\n",
       " 'pasta',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'pepper',\n",
       " 'peppers',\n",
       " 'per',\n",
       " 'perfect',\n",
       " 'perfection',\n",
       " 'perfectly',\n",
       " 'perhaps',\n",
       " 'person',\n",
       " 'pick',\n",
       " 'pickled',\n",
       " 'pickles',\n",
       " 'pie',\n",
       " 'piece',\n",
       " 'pieces',\n",
       " 'pig',\n",
       " 'pita',\n",
       " 'pizza',\n",
       " 'pizzas',\n",
       " 'places',\n",
       " 'plain',\n",
       " 'plan',\n",
       " 'plate',\n",
       " 'plates',\n",
       " 'platter',\n",
       " 'pleasant',\n",
       " 'please',\n",
       " 'plenty',\n",
       " 'plus',\n",
       " 'pm',\n",
       " 'poached',\n",
       " 'point',\n",
       " 'popular',\n",
       " 'pork',\n",
       " 'portion',\n",
       " 'portions',\n",
       " 'pot',\n",
       " 'potato',\n",
       " 'potatoes',\n",
       " 'prefer',\n",
       " 'prepared',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'priced',\n",
       " 'prices',\n",
       " 'pricey',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'pudding',\n",
       " 'pulled',\n",
       " 'put',\n",
       " 'quality',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'quiet',\n",
       " 'quite',\n",
       " 'ramen',\n",
       " 'rare',\n",
       " 'rather',\n",
       " 'rating',\n",
       " 'ravioli',\n",
       " 'raw',\n",
       " 'read',\n",
       " 'reading',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'reasonable',\n",
       " 'reasonably',\n",
       " 'recently',\n",
       " 'recommend',\n",
       " 'recommended',\n",
       " 'red',\n",
       " 'refreshing',\n",
       " 'regular',\n",
       " 'remember',\n",
       " 'reservation',\n",
       " 'reservations',\n",
       " 'rest',\n",
       " 'restaurant',\n",
       " 'restaurants',\n",
       " 'return',\n",
       " 'review',\n",
       " 'reviews',\n",
       " 'rib',\n",
       " 'ribs',\n",
       " 'rice',\n",
       " 'rich',\n",
       " 'ricotta',\n",
       " 'right',\n",
       " 'risotto',\n",
       " 'roast',\n",
       " 'roasted',\n",
       " 'roll',\n",
       " 'rolls',\n",
       " 'romantic',\n",
       " 'room',\n",
       " 'round',\n",
       " 'rude',\n",
       " 'run',\n",
       " 'rush',\n",
       " 'said',\n",
       " 'sake',\n",
       " 'salad',\n",
       " 'salads',\n",
       " 'salmon',\n",
       " 'salt',\n",
       " 'salty',\n",
       " 'sandwich',\n",
       " 'sandwiches',\n",
       " 'sangria',\n",
       " 'sat',\n",
       " 'satisfied',\n",
       " 'saturday',\n",
       " 'sauce',\n",
       " 'sauces',\n",
       " 'sausage',\n",
       " 'savory',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scallops',\n",
       " 'sea',\n",
       " 'seafood',\n",
       " 'seasoned',\n",
       " 'seat',\n",
       " 'seated',\n",
       " 'seating',\n",
       " 'seats',\n",
       " 'second',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'selection',\n",
       " 'seriously',\n",
       " 'serve',\n",
       " 'served',\n",
       " 'server',\n",
       " 'servers',\n",
       " 'service',\n",
       " 'serving',\n",
       " 'sesame',\n",
       " 'set',\n",
       " 'several',\n",
       " 'share',\n",
       " 'shared',\n",
       " 'shop',\n",
       " 'short',\n",
       " 'show',\n",
       " 'shrimp',\n",
       " 'side',\n",
       " 'sides',\n",
       " 'sign',\n",
       " 'similar',\n",
       " 'simple',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'single',\n",
       " 'sister',\n",
       " 'sit',\n",
       " 'sitting',\n",
       " 'size',\n",
       " 'sized',\n",
       " 'skin',\n",
       " 'slice',\n",
       " 'slices',\n",
       " 'sliders',\n",
       " 'slightly',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'smaller',\n",
       " 'smoked',\n",
       " 'soft',\n",
       " 'soggy',\n",
       " 'solid',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'sort',\n",
       " 'soup',\n",
       " 'sour',\n",
       " 'space',\n",
       " 'spaghetti',\n",
       " 'special',\n",
       " 'specials',\n",
       " 'spice',\n",
       " 'spicy',\n",
       " 'spinach',\n",
       " 'split',\n",
       " 'spot',\n",
       " 'spots',\n",
       " 'sprouts',\n",
       " 'square',\n",
       " 'st',\n",
       " 'staff',\n",
       " 'stand',\n",
       " 'standard',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'started',\n",
       " 'stay',\n",
       " 'steak',\n",
       " 'steamed',\n",
       " 'stick',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'stopped',\n",
       " 'store',\n",
       " 'street',\n",
       " 'strong',\n",
       " 'stuff',\n",
       " 'stuffed',\n",
       " 'style',\n",
       " 'sugar',\n",
       " 'suggest',\n",
       " 'summer',\n",
       " 'sunday',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'surprise',\n",
       " 'surprised',\n",
       " 'surprisingly',\n",
       " 'sushi',\n",
       " 'sweet',\n",
       " 'table',\n",
       " 'tables',\n",
       " 'taco',\n",
       " 'tacos',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'takes',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'tapas',\n",
       " 'taste',\n",
       " 'tasted',\n",
       " 'tastes',\n",
       " 'tasting',\n",
       " 'tasty',\n",
       " 'tea',\n",
       " 'tell',\n",
       " 'tender',\n",
       " 'terrible',\n",
       " 'texture',\n",
       " 'th',\n",
       " 'thai',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thick',\n",
       " 'thin',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tiny',\n",
       " 'tip',\n",
       " 'toast',\n",
       " 'today',\n",
       " 'tofu',\n",
       " 'together',\n",
       " 'told',\n",
       " 'tomato',\n",
       " 'tomatoes',\n",
       " 'took',\n",
       " 'top',\n",
       " 'topped',\n",
       " 'toppings',\n",
       " 'total',\n",
       " 'totally',\n",
       " 'touch',\n",
       " 'town',\n",
       " 'traditional',\n",
       " 'treat',\n",
       " 'tried',\n",
       " 'trip',\n",
       " 'true',\n",
       " 'truffle',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'tuna',\n",
       " 'turned',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'type',\n",
       " 'typical',\n",
       " 'understand',\n",
       " 'unfortunately',\n",
       " 'unique',\n",
       " 'unless',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'usually',\n",
       " 'value',\n",
       " 'variety',\n",
       " 'vegetable',\n",
       " 'vegetables',\n",
       " 'vegetarian',\n",
       " 'veggie',\n",
       " 'veggies',\n",
       " 'vibe',\n",
       " 'village',\n",
       " 'visit',\n",
       " 'visiting',\n",
       " 'waffles',\n",
       " 'wait',\n",
       " 'waited',\n",
       " 'waiter',\n",
       " 'waiters',\n",
       " 'waiting',\n",
       " 'waitress',\n",
       " 'walk',\n",
       " 'walked',\n",
       " 'walking',\n",
       " 'wall',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'warm',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'way',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'weeks',\n",
       " 'weird',\n",
       " 'well',\n",
       " 'went',\n",
       " 'west',\n",
       " 'whatever',\n",
       " 'white',\n",
       " 'whole',\n",
       " 'wife',\n",
       " 'window',\n",
       " 'wine',\n",
       " 'wines',\n",
       " 'wings',\n",
       " 'wish',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wonderful',\n",
       " 'word',\n",
       " 'work',\n",
       " 'working',\n",
       " 'world',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'wow',\n",
       " 'write',\n",
       " 'wrong',\n",
       " 'yeah',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yelp',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'york',\n",
       " 'yum',\n",
       " 'yummy']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features of the count vectorizers\n",
    "#cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f30bc0b1-04dd-4e05-ba04-89a72d22f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer()\n",
    "X = tf_transformer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab32e846-5005-49d9-9e5a-4f87ddc71d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidfVectorizer = TfidfVectorizer(max_features =1000)\n",
    "X = tfidfVectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c44260e-a0b8-4e82-9381-15daa75ee7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train_s, X_test_s , y_train_s, y_test_s = train_test_split(X, y, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12712a42-add5-4054-ab9d-df43d08b7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# # Naive Bayes is a statistical classification technique based on Bayes Theorem\n",
    "# # common classifier used in sentiment analysis is the Naive Bayes Classifier.\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting\n",
    "# from sklearn.ensemble import HistGradientBoostingClassifier # this is experimental\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# classifiers = [GradientBoostingClassifier(),GaussianNB(),HistGradientBoostingClassifier(),\n",
    "#                RandomForestClassifier(),LogisticRegression()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86108409-0380-4b75-bddc-31088cae5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "# for classifier in classifiers:\n",
    "#     classifier.fit(X_train_s,y_train_s)\n",
    "#     print(f'The {classifier}  Accuracy  is {accuracy_score(y_test_s,classifier.predict(X_test_s)) }' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e26d4eb-b182-4d34-b716-43bd8bd70942",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = original_df['review']\n",
    "labels = original_df['target']\n",
    "X_train, X_test , y_train, y_test = train_test_split(docs, labels , random_state = 42, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "224c22ae-a469-4752-966d-f55074fbd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "\n",
    "X_train = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_train]\n",
    "X_test = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "486af7a8-dac6-40fa-b4e5-dfaea77d817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_length = 100\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "851fdd99-2b20-467a-99e6-3c3d00b44d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1 = Sequential([\n",
    "    Embedding(vocab_size, 8, input_length=max_length),\n",
    "   Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "  Dense(10, activation='relu'),\n",
    "  Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e5a5002-9686-461e-a71d-a7d757e587ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58a2c7c1-cfbc-4545-9468-bf3b316fcdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6703/6703 [==============================] - 27s 4ms/step - loss: 0.3258 - acc: 0.8954 - val_loss: 0.3038 - val_acc: 0.8982\n",
      "Epoch 2/20\n",
      "6703/6703 [==============================] - 28s 4ms/step - loss: 0.2979 - acc: 0.8971 - val_loss: 0.3044 - val_acc: 0.8982\n",
      "Epoch 3/20\n",
      "6703/6703 [==============================] - 27s 4ms/step - loss: 0.2871 - acc: 0.8979 - val_loss: 0.3079 - val_acc: 0.8982\n",
      "Epoch 4/20\n",
      "6703/6703 [==============================] - 27s 4ms/step - loss: 0.2742 - acc: 0.8986 - val_loss: 0.3160 - val_acc: 0.8980\n",
      "Epoch 5/20\n",
      "6703/6703 [==============================] - 28s 4ms/step - loss: 0.2597 - acc: 0.8988 - val_loss: 0.3303 - val_acc: 0.8962\n",
      "Epoch 6/20\n",
      "6703/6703 [==============================] - 28s 4ms/step - loss: 0.2471 - acc: 0.9011 - val_loss: 0.3536 - val_acc: 0.8963\n",
      "Epoch 7/20\n",
      "6703/6703 [==============================] - 28s 4ms/step - loss: 0.2347 - acc: 0.9042 - val_loss: 0.3542 - val_acc: 0.8839\n",
      "Epoch 8/20\n",
      "6703/6703 [==============================] - 28s 4ms/step - loss: 0.2238 - acc: 0.9072 - val_loss: 0.3677 - val_acc: 0.8844\n",
      "Epoch 9/20\n",
      "6703/6703 [==============================] - 28s 4ms/step - loss: 0.2148 - acc: 0.9104 - val_loss: 0.3800 - val_acc: 0.8705\n",
      "Epoch 10/20\n",
      "6703/6703 [==============================] - 28s 4ms/step - loss: 0.2057 - acc: 0.9142 - val_loss: 0.4005 - val_acc: 0.8822\n",
      "Epoch 11/20\n",
      "6703/6703 [==============================] - 29s 4ms/step - loss: 0.1989 - acc: 0.9164 - val_loss: 0.4078 - val_acc: 0.8659\n",
      "Epoch 12/20\n",
      "6703/6703 [==============================] - 30s 4ms/step - loss: 0.1916 - acc: 0.9201 - val_loss: 0.4256 - val_acc: 0.8746\n",
      "Epoch 13/20\n",
      "6703/6703 [==============================] - 34s 5ms/step - loss: 0.1856 - acc: 0.9225 - val_loss: 0.4408 - val_acc: 0.8740\n",
      "Epoch 14/20\n",
      "6703/6703 [==============================] - 36s 5ms/step - loss: 0.1814 - acc: 0.9232 - val_loss: 0.4565 - val_acc: 0.8566\n",
      "Epoch 15/20\n",
      "6703/6703 [==============================] - 34s 5ms/step - loss: 0.1771 - acc: 0.9257 - val_loss: 0.4642 - val_acc: 0.8505\n",
      "Epoch 16/20\n",
      "6703/6703 [==============================] - 37s 6ms/step - loss: 0.1715 - acc: 0.9281 - val_loss: 0.5235 - val_acc: 0.8674\n",
      "Epoch 17/20\n",
      "6703/6703 [==============================] - 39s 6ms/step - loss: 0.1678 - acc: 0.9290 - val_loss: 0.5135 - val_acc: 0.8684\n",
      "Epoch 18/20\n",
      "6703/6703 [==============================] - 40s 6ms/step - loss: 0.1641 - acc: 0.9307 - val_loss: 0.5122 - val_acc: 0.8479\n",
      "Epoch 19/20\n",
      "6703/6703 [==============================] - 45s 7ms/step - loss: 0.1598 - acc: 0.9326 - val_loss: 0.5738 - val_acc: 0.8768\n",
      "Epoch 20/20\n",
      "6703/6703 [==============================] - 44s 7ms/step - loss: 0.1556 - acc: 0.9343 - val_loss: 0.5883 - val_acc: 0.8655\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "505d63f2-6cb9-4b31-8a35-06b60ef668f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6703/6703 [==============================] - 12s 2ms/step - loss: 0.1411 - acc: 0.9386\n",
      "Training Accuracy is 93.85859966278076 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model1.evaluate(X_train,y_train)\n",
    "print('Training Accuracy is {} '.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79561e09-7821-4beb-9b56-76e82f571fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2235/2235 [==============================] - 4s 2ms/step - loss: 0.5883 - acc: 0.8655\n",
      "Testing Accuracy is 86.54806613922119 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model1.evaluate(X_test,y_test)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38f5ef1c-c912-41fc-9f5b-43c8f1d10fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d94f751-6e79-4dfd-ae2a-aaa05769fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_train = [round(x[0]) for x in y_pred_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07b9fea8-11c5-46cf-be5e-e3df26679430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10272,  11558],\n",
       "       [  1615, 191050]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, rounded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "516e4a80-a3c8-416a-9a0c-3647be18bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b53f93e5-5877-4433-9036-46b5bbe00689",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded = [round(x[0]) for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1aa78065-7104-4096-9c9f-fb3a3e9bce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  589,  6688],\n",
       "       [ 2930, 61292]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d02ad6-354f-4b98-b6c9-5e82808861eb",
   "metadata": {},
   "source": [
    "# Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a3cadba-694c-4b4b-9941-af6b5edd4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = original_df['review']\n",
    "y1 = original_df['target']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1 , y_train1, y_test1 = train_test_split(X1, y1 , test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "518e3f30-1ff3-45a8-8790-ce4f21422e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 5000\n",
    "oov_token = \"<OOV>\"\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2404b81-7c7d-4b4d-8334-e203a4b97408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(X_train1)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fe95da9-fee4-4b06-9f6e-3f09ba4feb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "padding_type = \"post\"\n",
    "trunction_type=\"post\"\n",
    "X_train_padded = pad_sequences(X_train_sequences,maxlen=max_length, padding=padding_type,\n",
    "                       truncating=trunction_type)\n",
    "X_test_padded = pad_sequences(X_test_sequences,maxlen=max_length,\n",
    "                               padding=padding_type, truncating=trunction_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5cf1d-608a-4af8-a70f-38275a911429",
   "metadata": {},
   "source": [
    "# Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67fad0ea-ecec-432e-ac55-f2d24f60cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ccef7-07a4-4472-bd88-204f5f64b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl http://nlp.stanford.edu/data/glove.6B.zip\n",
    "#!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4fd75-347f-4cc5-89e7-2d0933348dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"http://nlp.stanford.edu/data/glove.6B.zip \\\n",
    "# -O /tmp/glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cee0c-38c9-47b4-a50a-0ce720928ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate \\\n",
    "# http://nlp.stanford.edu/data/glove.6B.zip \\\n",
    "# -O /tmp/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cf591c3-4c7a-4540-8271-5e59b61716b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./glove.6B.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/tmp/glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36e9175f-203f-467d-9472-f303c4318fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('/tmp/glove/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c946699c-437f-4705-a938-f6412a770bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.85034  ,  0.33358  , -0.65889  , -0.49871  ,  0.36585  ,\n",
       "       -0.19245  ,  0.25658  , -0.053408 ,  0.31474  ,  0.2443   ,\n",
       "        0.29337  , -0.44917  ,  0.15175  ,  0.39314  , -0.31786  ,\n",
       "        0.060525 ,  0.81775  , -0.38847  ,  0.76761  , -1.1041   ,\n",
       "       -0.1544   ,  0.31655  , -0.37238  , -0.11485  ,  0.51635  ,\n",
       "       -0.39289  ,  0.16301  , -0.2532   , -0.50976  ,  0.15201  ,\n",
       "        0.27808  ,  0.52522  , -0.38815  , -0.3472   , -0.61818  ,\n",
       "        0.17022  ,  0.12251  , -0.24191  , -0.38877  , -0.53176  ,\n",
       "       -0.46987  , -0.70502  , -0.62126  , -0.38689  , -0.85637  ,\n",
       "       -0.41003  , -0.47487  , -0.21083  , -0.81338  , -0.52398  ,\n",
       "        0.49894  ,  0.37909  ,  0.55428  ,  1.123    , -0.42121  ,\n",
       "       -1.5674   , -0.56892  ,  0.40819  ,  1.7949   ,  0.16856  ,\n",
       "       -0.0029332,  0.28786  , -0.90088  , -0.094214 ,  0.79993  ,\n",
       "       -0.39096  ,  0.76286  ,  0.71307  ,  0.13194  , -0.40756  ,\n",
       "       -0.18687  ,  0.89562  ,  0.46867  , -0.0028801,  0.025306 ,\n",
       "        1.0084   ,  0.17135  ,  0.59742  , -1.1003   ,  0.49305  ,\n",
       "        0.41782  ,  0.17285  , -0.49474  ,  0.087837 , -0.9669   ,\n",
       "       -1.092    ,  0.33896  , -0.51288  ,  0.24643  ,  0.27141  ,\n",
       "        0.24206  , -0.21707  ,  0.55035  ,  0.0082243, -0.45572  ,\n",
       "        0.13528  , -0.043146 , -0.41408  ,  0.70051  ,  0.18775  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index.get(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9474b59c-795c-4a69-b60a-afae51d2e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(X) + 1, max_length))\n",
    "for word, i in X1.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39835fa6-1047-4af5-a98b-64136b8c5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=len(X) + 1,\n",
    "                            output_dim=max_length,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bceeb90c-bdc0-49c4-ba8b-3a0b478a67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    embedding_layer,\n",
    "  Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "  Dense(10, activation='relu'),\n",
    "  Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab089270-3455-4027-9584-c17a7d54ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "300dcfa7-84a3-4180-99ed-ac95e64748a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7150/7150 [==============================] - 279s 39ms/step - loss: 0.4462 - accuracy: 0.8962 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 2/20\n",
      "7150/7150 [==============================] - 312s 44ms/step - loss: 0.3301 - accuracy: 0.8977 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 3/20\n",
      "7150/7150 [==============================] - 314s 44ms/step - loss: 0.3320 - accuracy: 0.8969 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 4/20\n",
      "7150/7150 [==============================] - 261s 36ms/step - loss: 0.3280 - accuracy: 0.8987 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 5/20\n",
      "7150/7150 [==============================] - 239s 33ms/step - loss: 0.3295 - accuracy: 0.8980 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 6/20\n",
      "7150/7150 [==============================] - 244s 34ms/step - loss: 0.3300 - accuracy: 0.8977 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 7/20\n",
      "7150/7150 [==============================] - 234s 33ms/step - loss: 0.3291 - accuracy: 0.8981 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 8/20\n",
      "7150/7150 [==============================] - 232s 32ms/step - loss: 0.3284 - accuracy: 0.8985 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 9/20\n",
      "7150/7150 [==============================] - 229s 32ms/step - loss: 0.3254 - accuracy: 0.8999 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 10/20\n",
      "7150/7150 [==============================] - 300s 42ms/step - loss: 0.3313 - accuracy: 0.8971 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 11/20\n",
      "7150/7150 [==============================] - 323s 45ms/step - loss: 0.3288 - accuracy: 0.8983 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 12/20\n",
      "7150/7150 [==============================] - 319s 45ms/step - loss: 0.3317 - accuracy: 0.8970 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 13/20\n",
      "7150/7150 [==============================] - 319s 45ms/step - loss: 0.3267 - accuracy: 0.8993 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 14/20\n",
      "7150/7150 [==============================] - 282s 39ms/step - loss: 0.3291 - accuracy: 0.8982 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 15/20\n",
      "7150/7150 [==============================] - 177s 25ms/step - loss: 0.3290 - accuracy: 0.8982 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 16/20\n",
      "7150/7150 [==============================] - 165s 23ms/step - loss: 0.3282 - accuracy: 0.8986 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 17/20\n",
      "7150/7150 [==============================] - 164s 23ms/step - loss: 0.3256 - accuracy: 0.8998 - val_loss: 0.3263 - val_accuracy: 0.8995\n",
      "Epoch 18/20\n",
      "7150/7150 [==============================] - 163s 23ms/step - loss: 0.3296 - accuracy: 0.8979 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 19/20\n",
      "7150/7150 [==============================] - 164s 23ms/step - loss: 0.3310 - accuracy: 0.8973 - val_loss: 0.3262 - val_accuracy: 0.8995\n",
      "Epoch 20/20\n",
      "7150/7150 [==============================] - 163s 23ms/step - loss: 0.3307 - accuracy: 0.8974 - val_loss: 0.3262 - val_accuracy: 0.8995\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_padded, y_train1, epochs=20, validation_data=(X_test_padded, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb351af9-cf14-4226-9955-3e6b9f684e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788/1788 [==============================] - 16s 9ms/step - loss: 0.3262 - accuracy: 0.8995\n",
      "Testing Accuracy is 89.9473786354065 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded,y_test1)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general-env",
   "language": "python",
   "name": "general-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
